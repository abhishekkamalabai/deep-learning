# -*- coding: utf-8 -*-
"""Copy of Handwritten digit -CNN distri.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hXTN9YWwl4TTf2K0NXtUDqMz4RlOWS8I

# Handwritten Digit recognition using CNN

# import the libararies
"""

from tensorflow import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)

"""# Preprocessing data"""

num_classes=10
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
input_shape = (28, 28, 1)

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train = x_train/255
x_test = x_test/255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

"""# Create the model

![image.png](attachment:image.png)

This code defines a convolutional neural network (CNN) architecture for the MNIST dataset, suitable for image classification tasks. The model consists of convolutional layers, pooling layers, dropout layers, and fully connected layers, and is compiled with appropriate loss function, optimizer, and metrics.

Understanding the default values of the parameters in different functions calls will help you.

<b>Hyperparameter Setting</b>: <br>
`batch_size`: <br>
Determines the number of samples processed in a single batch during training. A larger batch size can speed up training but might require more memory. <br>

`num_classes`: <br>
Specifies the number of output classes, which is 10 for the MNIST dataset (digits 0-9). <br>

`epochs`: <br>
Defines the number of times the entire dataset is passed through the network during training.

<b>Model Architecture</b>: <br>
`Sequential Model`: <br>
Creates a sequential model, where layers are added sequentially. <br>

<b>Convolutional Layers</b>: <br>
`Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)`:<br>
* Adds a 2D convolutional layer with 32 filters, each of size 3x3.
* ses the ReLU activation function to introduce non-linearity.
* Specifies the input shape of the images (it's already defined).

`Conv2D(64, (3, 3), activation='relu')`: <br>
Adds another convolutional layer with 64 filters of size 3x3, also using ReLU activation. <br>

<b>Pooling Layer</b>: <br>
`MaxPooling2D(pool_size=(2, 2))`: <br>
Downsamples the feature maps by taking the maximum value in 2x2 patches. This reduces the dimensionality and computational cost. <br>

<b>Dropout Layer</b>: <br>
`Dropout(0.25)`: <br>
Randomly sets 25% of the input units to 0 during training. This helps prevent overfitting by introducing noise and making the model more robust. <br>

<b>Flatten Layer</b>: <br>
Flattens the 2D feature maps into a 1D vector. <br>

<b>Dense Layers</b>: <br>
`Dense(256, activation='relu')`: <br>
Adds a fully connected layer with 256 units, using ReLU activation. <br>

`Dense(num_classes, activation='softmax')`: <br>
Adds a final fully connected layer with 10 units (equal to the number of classes) and uses the softmax activation function to produce probability distributions for each class. <br>

<b>Model Compilation</b>: <br>
<b>Loss Function</b>: <br>
`keras.losses.categorical_crossentropy` is used as the loss function, which is appropriate for multi-class classification problems. <br>

<b>Optimizer</b>:  <br>
`keras.optimizers.Adadelta()` is used as the optimization algorithm. Adadelta is an adaptive learning rate algorithm that automatically adjusts the learning rate during training. <br>

<b>Metrics</b>: <br>
`accuracy` is used as the metric to evaluate the model's performance.
"""

batch_size = 128
num_classes = 10
epochs = 10
# START YOUR CODE HERE
model = Sequential()
model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=input_shape))
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=['accuracy'])
# END YOUR CODE HERE

"""# Train the model"""

hist=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))
print("The model has successfully trained")
model.save('mnist.h5')
print("Saving the model as mnist.h5")

"""# Evaluate the model

The code snippet evaluates the trained CNN model on the test dataset and prints the test loss and accuracy. These metrics provide insights into the model's performance and help assess its ability to generalize to unseen data.

`score = model.evaluate(x_test, y_test, verbose=0)`:

* `model.evaluate`: <br>
This function evaluates the model's performance on a given dataset.

* `x_test`: <br>
The input data (images) from the test set.

* `y_test`: <br>
The corresponding true labels for the test set.

* `verbose=0`: <br>
This argument suppresses the progress bar that is typically displayed during evaluation, making the output more concise.

* The function returns a list containing the loss value and any specified metrics. In this case, since we've specified `metrics=['accuracy']`, the list will contain the test loss and test accuracy.

`print('Test loss:', score[0])`: <br>
This line prints the test loss, which is the first element in the score list. It indicates how well the model predicts the correct class for the test data. A lower loss value generally indicates better performance.

`print('Test accuracy:', score[1])`: <br>
This line prints the test accuracy, which is the second element in the score list. It represents the percentage of correct classifications on the test set. A higher accuracy indicates better performance.
"""

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

model.summary()

"""# Create GUI to predict digits"""

!pip install matplotlib ipywidgets Pillow

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from keras.models import load_model
from ipywidgets import widgets, interact

# Load your trained model
model = load_model('/content/mnist.h5')

# Global variables
canvas_size = 300
drawn_image = np.zeros((canvas_size, canvas_size))

def predict_digit(img):
    # Resize image to 28x28 pixels
    img = img.resize((28, 28))
    # Convert RGB to grayscale
    img = img.convert('L')
    img = np.array(img)
    # Reshaping to support our model input and normalizing
    img = img.reshape(1, 28, 28, 1)
    img = img / 255.0
    # Predicting the class
    res = model.predict([img])[0]
    return np.argmax(res), max(res)

def draw(event):
    global drawn_image
    if event.xdata is None or event.ydata is None:
        return
    x, y = int(event.xdata), int(event.ydata)
    r = 8
    # Draw a circle on the image
    drawn_image[y-r:y+r, x-r:x+r] = 255
    ax.imshow(drawn_image, cmap='gray')
    fig.canvas.draw()

def clear_canvas(_):
    global drawn_image
    drawn_image = np.zeros((canvas_size, canvas_size))
    ax.imshow(drawn_image, cmap='gray')
    fig.canvas.draw()

def classify_handwriting(_):
    global drawn_image
    # Convert the drawn image to a PIL image
    img = Image.fromarray(drawn_image).convert("RGB")
    # Predict the digit
    digit, acc = predict_digit(img)
    result_label.value = f'Predicted Digit: {digit}, Confidence: {int(acc * 100)}%'

# Create a figure for the canvas
fig, ax = plt.subplots(figsize=(5, 5))
ax.imshow(drawn_image, cmap='gray')
ax.axis('off')

# Connect the draw function to mouse motion
fig.canvas.mpl_connect('motion_notify_event', draw)

# Create buttons and output label
clear_button = widgets.Button(description="Clear")
clear_button.on_click(clear_canvas)

predict_button = widgets.Button(description="Predict")
predict_button.on_click(classify_handwriting)

result_label = widgets.Label(value="Draw a digit and press Predict")

# Display the UI components
display(fig.canvas, clear_button, predict_button, result_label)

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Load the model
model = tf.keras.models.load_model('mnist.h5')

# Load MNIST data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_test = np.expand_dims(x_test, -1) / 255.0  # Normalize and add channel dimension

# Test the model with some test images
for i in range(10):
    img = x_test[i]
    label = y_test[i]
    img = np.expand_dims(img, 0)  # Add batch dimension
    prediction = model.predict(img)[0]
    predicted_class = np.argmax(prediction)
    probability = np.max(prediction)

    # Plot the image and prediction
    plt.imshow(img[0, :, :, 0], cmap='gray')
    plt.title(f'Label: {label}, Prediction: {predicted_class}, Probability: {probability:.2f}')
    plt.show()

